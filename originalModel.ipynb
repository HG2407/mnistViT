{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from torchvision import datasets, transforms\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"csv\", data_files='C:/Users/train_images/cleaned_train_dataset.csv', split='train')\n",
    "test_dataset = load_dataset(\"csv\", data_files=\"C:/Users/test_images/cleaned_test_dataset.csv\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(train_dataset['Label']))\n",
    "print(set(test_dataset['Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(train_dataset['Label']))\n",
    "print(len(classes)) # classes: 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTImageProcessor\n",
    "\n",
    "model_name = 'google/vit-base-patch16-224'\n",
    "\n",
    "image_processor = ViTImageProcessor.from_pretrained(model_name, num_channels=3, image_mean=0.5, image_std=0.5)\n",
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(batch):\n",
    "    images = []\n",
    "    for i, image_name in enumerate(batch['Filename']):\n",
    "        image = Image.open(image_name)\n",
    "        image = image.convert('RGB')\n",
    "        images.append(image)\n",
    "    inputs = image_processor(images, return_tensors = 'pt')\n",
    "\n",
    "    inputs['label'] = batch['Label']\n",
    "\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared_train = train_dataset.with_transform(preprocess)\n",
    "# print(prepared_train['Filename'])\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "print(train_dataset[0]['Filename'])\n",
    "\n",
    "image = Image.open(train_dataset[0]['Filename'])\n",
    "example = image_processor(image, return_tensors='pt')\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_train = train_dataset.with_transform(preprocess)\n",
    "prepared_test = test_dataset.with_transform(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metric(p):\n",
    "    return accuracy_metric.compute(\n",
    "        predictions=np.argmax(p.predictions, axis=1),\n",
    "        references= p.label_ids\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./ModelOutput4',\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=2,\n",
    "    num_train_epochs=5,\n",
    "    evaluation_strategy='steps',\n",
    "    save_steps = 100,\n",
    "    eval_steps=100,\n",
    "    fp16=True,\n",
    "    logging_steps = 10,\n",
    "    learning_rate = 2e-3,\n",
    "    save_total_limit = 2,\n",
    "    remove_unused_columns = False,\n",
    "    push_to_hub = False,\n",
    "    load_best_model_at_end = True,\n",
    "    resume_from_checkpoint='./ModelOutput4',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification\n",
    "from torch import nn\n",
    "\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels = len(classes), ignore_mismatched_sizes=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    data_collator = collate_fn,\n",
    "    compute_metrics = compute_metric,\n",
    "    train_dataset = prepared_train,\n",
    "    eval_dataset = prepared_test,\n",
    "    tokenizer = image_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_results = trainer.train(resume_from_checkpoint=True)\n",
    "train_results = trainer.train()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()\n",
    "# accuracy around :- 0.0X (X -> random number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(prepared_test)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = test_dataset[779]['Filename']\n",
    "input = Image.open(image_name)\n",
    "label = test_dataset[779]['Label']\n",
    "test_labels = sorted(['office booths', 'bar furniture', 'appliances', 'kitchen', 'textile & rugs', 'office storage', 'office tables', 'bathroom', 'appliances & media', 'decorative accessories', 'showers & bathtubs', 'stairs & railings', 'tables', 'window treatment', 'botanical', 'washbasin', 'furniture components & accessories', 'people & pets', 'toilets & bidets', 'kitchen & dining furniture', 'structure', 'office partitions', 'transport', 'windows', 'landscapes', 'shapes', 'office furniture', 'bathroom storage', 'outdoor lighting', 'feature walls', 'lighting systems', 'bathroom furniture', 'lifestyle', 'food, drink, crockery', 'concept light', 'sofas and arm chairs', 'storage & organization', 'toilet & bidet', 'bathroom faucet', 'accessories', 'doors', 'outdoor furniture', 'building', 'office chairs', 'sports & hobbies', 'molding & millwork', 'bedroom furniture', 'bath accessories', 'ceiling designs', 'furniture', 'lamps', 'storage furniture', 'gardening & structure', 'sofas & arm chairs', 'lighting', 'kids furniture', 'wall decor', 'fireplace & services'])\n",
    "label = test_labels[label]\n",
    "print(image_name, input, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = image_processor(input, return_tensors='pt').to(device)\n",
    "with torch.no_grad():\n",
    "    logits = model(**features).logits\n",
    "\n",
    "print(logits)\n",
    "predicted_label = logits.argmax(-1).item()\n",
    "print(predicted_label)\n",
    "predicted_label = test_labels[predicted_label]\n",
    "print(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
